import operator
from dotenv import load_dotenv
from pydantic import BaseModel
from typing import Annotated, Literal
from langchain_core.messages import SystemMessage, ToolMessage,HumanMessage, AIMessage
from langgraph.graph import StateGraph, add_messages, END
from langgraph.prebuilt import ToolNode
from langchain_core.tools import tool, InjectedToolCallId
from datetime import datetime
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, RunnableConfig
from langchain_groq import ChatGroq
from researcher import graph as research_agent
from copywriter import graph as copywriter_agent


load_dotenv()

supervisor_prompt=open("prompts/supervisor.md","r").read()

class SupervisorState(BaseModel):
    """The state of the supervisor agent.
    
    The research_reports attribute is shared with the researcher agent. This allows us to share the research report between the researcher and copywriter agent."""
    messages:Annotated[list,add_messages]=[]
    research_reports:Annotated[list,operator.add]=[]
    task_description:str | None = None

@tool
async def handoff_to_subagent(
    agent_name:Literal["researcher","copywriter"],
    task_description:str,
    tool_call_id:Annotated[str,InjectedToolCallId]
):
    """Assign a task to a sub-agent: reseacher or copywriter.
    
    Args:
        agent_name: The name of the agent to handoff the task to. Valid agent names are resarcher and copywriter.
        task_description: The description of the task to be completed."""
    
    update={
        "task_description":task_description,
        "messages":[ToolMessage(
            name=f"handoff_to_{agent_name}",
            content=f"Successfully handed off task to {agent_name}",
            tool_call_id=tool_call_id,
        )]
    }

    # Return the Command primitive with the update to the state and specifying the next node to go to
    return Command(
        goto=f"call_{agent_name}",
        update=update
    )

async def call_researcher(state:SupervisorState, config:RunnableConfig):
    """Call the researcher agent.
    The agen is invoked only with the task description generated by the supervisor, so the context window is not cluttered with the full conversation history of the supervisor"""
    research_response=await research_agent.ainvoke(
        input={
            "messages":[HumanMessage(content=state.task_description)],
        },
        config=config
    )
    ai_message=AIMessage(name="researcher",content=research_response["messages"][-1].content)

    return {
        "research_reports":research_response['research_reports'],
        "messages":[ai_message]
    }

async def call_copywriter(state:SupervisorState,config:RunnableConfig):
        """Call the copywriter agent.
    
        The agent is invoked only with the task description generated by the supervisor, and any research reports that have been generated by the researcher.
        """
        copywriter_response=await copywriter_agent.ainvoke(
             input={
                  "messages":[HumanMessage(content=state.task_description)],
                  "research_reports":state.research_reports,
             },
             config=config
        )
        ai_message=AIMessage(name="copywriter",content=copywriter_response["messages"][-1].content)
        return {"messages":[ai_message]}

llm=ChatGroq(
    name="Supervisor",
    model="openai/gpt-oss-120b",
    reasoning_effort="medium",
)

tools=[handoff_to_subagent]
llm_with_tools=llm.bind_tools(tools,parallel_tool_calls=False)

async def supervisor(state:SupervisorState):
     """The main supervisor agent."""
     response=llm_with_tools.invoke([
          SystemMessage(content=supervisor_prompt.format(current_datetime=datetime.now()))
     ]+state.messages)
     return {"messages":[response]}

async def supervisor_router(state:SupervisorState)->str:
     """Route to the tools node if the supervisor makes a tool call."""
     if state.messages[-1].tool_calls:
          return "tools"
     return END

builder=StateGraph(SupervisorState)
builder.add_node(
     supervisor)
builder.add_node(
 "tools",ToolNode(tools)    
)

builder.add_node(call_researcher)
builder.add_node(call_copywriter)

builder.set_entry_point("supervisor")

builder.add_conditional_edges(
     "supervisor",
     supervisor_router,{
          "tools":"tools",
          END:END,
     }
)

# Now every time we call a sub-agent we need to route back to the supervisor
builder.add_edge("call_researcher", "supervisor")
builder.add_edge("call_copywriter", "supervisor")

graph = builder.compile(checkpointer=MemorySaver())